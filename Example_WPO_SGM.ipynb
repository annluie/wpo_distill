{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score-matching informed KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import lib.toy_data as toy_data\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix as pdsm\n",
    "import functions_WPO_SGM as LearnCholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"GPU is not available\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing for scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(' ')\n",
    "parser.add_argument('--data', choices=['swissroll', '8gaussians', 'pinwheel', 'circles', 'moons', '2spirals', 'checkerboard', 'rings'], type = str,default = '2spirals')\n",
    "parser.add_argument('--depth',help = 'number of hidden layers of score network',type =int, default = 5)\n",
    "parser.add_argument('--hiddenunits',help = 'number of nodes per hidden layer', type = int, default = 64)\n",
    "parser.add_argument('--niters',type = int, default = 50000)\n",
    "parser.add_argument('--batch_size', type = int,default = 64)\n",
    "parser.add_argument('--lr',type = float, default = 1e-3) \n",
    "parser.add_argument('--save',type = str,default = 'experiments/2D/')\n",
    "parser.add_argument('--train_kernel_size',type = int, default = 1000)\n",
    "parser.add_argument('--train_samples_size',type = int, default = 50000)\n",
    "parser.add_argument('--test_samples_size',type = int, default = 500)\n",
    "args = parser.parse_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kernel_size = args.train_kernel_size\n",
    "train_samples_size = args.train_samples_size\n",
    "test_samples_size = args.test_samples_size\n",
    "dataset = args.data \n",
    "save_directory = args.save + 'test_0402'+'/'\n",
    "\n",
    "print('save_directory',save_directory)\n",
    "\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "    print('Created directory ' + save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision matrix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cholesky factor model\n",
    "def construct_factor_model(dim:int, depth:int, hidden_units:int):\n",
    "    '''\n",
    "    Initializes neural network that models the Cholesky factor of the precision matrix # For nD examples (in theory)\n",
    "    '''\n",
    "    chain = []\n",
    "    chain.append(nn.Linear(dim,int(hidden_units),bias =True)) \n",
    "    chain.append(nn.GELU())\n",
    "\n",
    "    for _ in range(depth-1):\n",
    "        chain.append(nn.Linear(int(hidden_units),int(hidden_units),bias = True))\n",
    "        chain.append(nn.GELU())\n",
    "    chain.append(nn.Linear(int(hidden_units),int(dim*(dim+1)/2),bias = True)) \n",
    "\n",
    "    return nn.Sequential(*chain)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(factornet, kernel_centers, num_test_sample):\n",
    "    '''\n",
    "    Evaluate the model by computing the average total loss over 10 batch of testing samples\n",
    "    '''\n",
    "    total_loss_sum = 0\n",
    "    device = kernel_centers.device\n",
    "    for i in range(10):\n",
    "        p_samples = toy_data.inf_train_gen(dataset,batch_size = num_test_sample)\n",
    "        testing_samples = torch.tensor(p_samples).to(dtype = torch.float32).to(device)\n",
    "        total_loss = LearnCholesky.score_implicit_matching(factornet,kernel_centers,testing_samples)\n",
    "        total_loss_sum += total_loss.item()\n",
    "    average_total_loss = total_loss_sum / 10\n",
    "    return average_total_loss\n",
    "\n",
    "def save_training_slice_cov(factornet, means, epoch, lr, batch_size, loss_value, save):\n",
    "    '''\n",
    "    Save the training slice of the density plot\n",
    "    '''\n",
    "    plot_axis = means.max().item() * 1.1\n",
    "    device = means.device\n",
    "    # Create x as a NumPy array\n",
    "    x_np = np.meshgrid(np.linspace(-plot_axis, plot_axis, 200), np.linspace(-plot_axis, plot_axis, 200))\n",
    "    x_np = np.stack(x_np, axis=-1).reshape(-1, 2)\n",
    "\n",
    "    x = torch.tensor(x_np, dtype=torch.float32, device=device)\n",
    "    precisions = LearnCholesky.vectors_to_precision(factornet(means),2)\n",
    "    density = LearnCholesky.mog_density(x, means, precisions)\n",
    "    density = density.reshape(200, 200).T\n",
    "\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.subplot(1, 2, 1) \n",
    "    plt.contourf(np.linspace(-plot_axis, plot_axis, 200), np.linspace(-plot_axis, plot_axis, 200), density.detach().cpu().numpy(), cmap='viridis')\n",
    "    plt.axis('square')\n",
    "    plt.colorbar()     \n",
    "    \n",
    "    plt.subplot(1, 2, 2) \n",
    "    plt.contourf(np.linspace(-plot_axis, plot_axis, 200), np.linspace(-plot_axis, plot_axis, 200), density.detach().cpu().numpy(), cmap='viridis')\n",
    "    # Plot the centers\n",
    "    num_components = torch.min(torch.tensor([means.shape[0], 400]))\n",
    "    plot_centers = means[:num_components].detach().cpu().numpy()\n",
    "    plt.scatter(plot_centers[:,1], plot_centers[:,0], s=0.2, c='r')\n",
    "    plt.axis('square')\n",
    "    # plt.colorbar()    \n",
    "    plt.title(f'Epoch: {epoch}, Loss: {loss_value:.3e}')\n",
    "             \n",
    "    plt.tight_layout()  # Improve subplot spacing\n",
    "\n",
    "    # Save the figure\n",
    "    lr_str = f'{lr:.2e}'\n",
    "    if save is not None:\n",
    "        plt.savefig(f'{save}batch_size_{batch_size}lr_{lr_str}_epoch_{epoch}.png')\n",
    "\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize score network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = args.depth\n",
    "hidden_units = args.hiddenunits\n",
    "factornet = construct_factor_model(2, depth,hidden_units).to(device).to(dtype = torch.float32)\n",
    "\n",
    "lr = args.lr\n",
    "optimizer = optim.Adam(factornet.parameters(), lr=args.lr)\n",
    "\n",
    "p_samples = toy_data.inf_train_gen(dataset,batch_size = train_samples_size)\n",
    "training_samples = torch.tensor(p_samples).to(dtype = torch.float32).to(device)\n",
    "centers  = torch.tensor(toy_data.inf_train_gen(dataset, batch_size = train_kernel_size)).to(dtype = torch.float32).to(device)\n",
    "\n",
    "torch.save(centers, save_directory + 'centers.pt')\n",
    "\n",
    "epochs = args.niters\n",
    "batch_size = args.batch_size\n",
    "\n",
    "# Training the score network\n",
    "loss = evaluate_model(factornet, centers, test_samples_size)\n",
    "formatted_loss = f'{loss:.3e}'  # Format the average with up to 1e-3 precision\n",
    "print(f'Before train, Average total_loss: {formatted_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset\n",
    "dataset = args.data\n",
    "# dataset = 'swissroll'\n",
    "means  = torch.tensor(toy_data.inf_train_gen(dataset, batch_size = 1000)).to(dtype = torch.float32)\n",
    "data_dim = means.shape[1]\n",
    "\n",
    "blah = pd.DataFrame(means)\n",
    "pdsm(blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(epochs):\n",
    "    # samples_toydata\n",
    "    randind = torch.randint(0,train_samples_size,[batch_size,])\n",
    "    samples = training_samples[randind,:]\n",
    "\n",
    "    loss = LearnCholesky.score_implicit_matching(factornet,samples,centers)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if not step % 4000:\n",
    "        loss_value = loss.item()\n",
    "        print(f'Step: {step}, Loss value: {loss_value:.3e}')\n",
    "\n",
    "    if not step % 20000:\n",
    "        loss0 = evaluate_model(factornet, centers, test_samples_size)\n",
    "        save_training_slice_cov(factornet, centers, step, lr, batch_size, loss0, save_directory)\n",
    "\n",
    "formatted_loss = f'{loss:.3e}'  # Format the average with up to 1e-3 precision\n",
    "print(f'After train, Average total_loss: {formatted_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from trained model\n",
    "# and plot density\n",
    "randind = torch.randint(0,1000,[1000,])\n",
    "centers = means[randind,:].to(device)\n",
    "precisions = LearnCholesky.vectors_to_precision(factornet(centers),data_dim)\n",
    "\n",
    "LearnCholesky.scatter_samples_from_model(centers, precisions, 0, 1,save_path=save_directory + 'samples.png')\n",
    "LearnCholesky.plot_density_2d_marg(centers,factornet,save_path=save_directory + 'density.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
